# Adapted from :
# https://github.com/DeepWave-KAUST/DeepFWIHessian/blob/main/deepinvhessian/train.py
# https://github.com/DeepWave-KAUST/DeepFWIHessian/blob/main/deepinvhessian_old/prepare_data.py

from typing import Callable, List, Dict
import numpy as np
import torch
from torch import nn, optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import TensorDataset, DataLoader
from tqdm.notebook import tqdm

def train(network, dataloader, optimizer, loss_fn, epochs, device):
    loss = []
    network.train()
    for ep in tqdm(range(epochs)):
        running_loss = 0
        for sample in dataloader:
            optimizer.zero_grad()
            x1, y1 = sample[0].to(device), sample[1].unsqueeze(1).to(device)
            dm_pred = network(x1)
            loss_ = loss_fn(dm_pred, y1)
            running_loss += loss_.item()
            loss_.backward()
            optimizer.step()

        loss.append(running_loss/len(dataloader))

        print(f'Training Epoch {ep+1}, Loss = {loss[-1]}')

        # optimizer_unet.param_groups[-1]['lr'] = lr_init
    return loss


'''  prepare data for pytorch '''
def prepare_data(x, d, y, patch_size, slide, batch_size):
    
    pd = (1, 0, 0, 0)
    pad_replicate = nn.ReplicationPad2d(pd)
    assert  x.shape == y.shape , 'shape should be equal, ' 
    
    x = pad_replicate(x.unsqueeze(0)).squeeze(0).float().cuda()
    d = pad_replicate(d.unsqueeze(0)).squeeze(0).float().cuda()
    y = pad_replicate(y.unsqueeze(0)).squeeze(0).float().cuda()

    k = patch_size
    kk = slide

    X, D, L, Y = [], [], [], []
    for xi in range(int(x.shape[0] // (k/kk))):
        for yi in range(int(x.shape[1] // (k/kk))):
            patch1 = x[xi*(k//kk):xi*(k//kk)+k, yi*(k//kk):yi*(k//kk)+k]
            patchd = d[xi*(k//kk):xi*(k//kk)+k, yi*(k//kk):yi*(k//kk)+k]
            patch2 = y[xi*(k//kk):xi*(k//kk)+k, yi*(k//kk):yi*(k//kk)+k]

            if patch1.shape == (k, k):    
                X.append(patch1)
                D.append(patchd)
                Y.append(patch2)

    X = torch.stack(X)
    D = torch.stack(D)
    Y = torch.stack(Y)
    X = torch.cat([X.unsqueeze(1), D.unsqueeze(1)], dim=1)

    dm_dataset = TensorDataset(X, Y)
    train_dataloader = DataLoader(dm_dataset, batch_size=batch_size, shuffle=True, drop_last=False)

    return train_dataloader